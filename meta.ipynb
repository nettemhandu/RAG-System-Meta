{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOPKMwL8T5QuBJfmlkxFt9i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%pip install -q \\\n","  llama-index \\\n","  llama-index-llms-openrouter \\\n","  llama-index-embeddings-huggingface \\\n","  llama-index-readers-file \\\n","  llama-index-packs-fusion-retriever \\\n","  sentence-transformers \\\n","  nest-asyncio \\\n","  requests\n","\n","print(\"âœ… Installation complete\")"],"metadata":{"id":"CvX-O69Sr6hY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Connect to the AI model (Step 2)\n","\n","Here you:\n","\n","- Import core libraries\n","- Enter your **OpenRouter API key**\n","- Configure the **Llama model**\n","- Configure the **embedding model**\n","- Tell `llama-index` to use them\n","\n","Run this cell **after** Step 1."],"metadata":{"id":"-8-XohU-sa41"}},{"cell_type":"code","source":["import os\n","from getpass import getpass\n","import nest_asyncio\n","\n","nest_asyncio.apply()\n","\n","from llama_index.core import Settings\n","from llama_index.llms.openrouter import OpenRouter\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","\n","# Ask for your OpenRouter API key (input is hidden like a password)\n","os.environ[\"OPENROUTER_API_KEY\"] = getpass(\"Enter your OpenRouter API key: \")\n","\n","# Configure the LLM (Meta Llama via OpenRouter)\n","llm = OpenRouter(\n","    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n","    model=\"meta-llama/llama-3.3-70b-instruct:free\",\n","    max_tokens=512,\n","    temperature=0.1,  # Low = more precise, less â€œcreativeâ€\n","    timeout=60,\n","    system_prompt=(\n","        \"You are an expert RAG system that answers ONLY using the provided context. \"\n","        \"Never hallucinate. Never guess. If the answer is not in the context, say so. \"\n","        \"Provide short, clear, factual responses with 2â€“4 evidence bullets.\"\n","    ),\n",")\n","\n","# Configure the embedding model\n","embed_model = HuggingFaceEmbedding(\n","    model_name=\"BAAI/bge-small-en-v1.5\"\n",")\n","\n","# Register both with LlamaIndex settings\n","Settings.llm = llm\n","Settings.embed_model = embed_model\n","\n","print(\"âœ… AI model and settings are ready to use\")"],"metadata":{"id":"ieYBZg-FshAh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Download the PDF from Google Drive (Step 3)\n","\n","This step:\n","\n","1. Asks you for a **Google Drive link** to your PDF\n","2. Extracts the **file ID** from the link\n","3. Downloads the PDF into a local `data/` folder\n","4. Saves it as `data/source.pdf`\n","\n","Supported link formats include:\n","\n","- `https://drive.google.com/file/d/<FILE_ID>/view?...`\n","- `https://drive.google.com/open?id=<FILE_ID>`"],"metadata":{"id":"DLhe8wf4wZQA"}},{"cell_type":"code","source":["import os\n","import re\n","import requests\n","\n","def download_pdf_from_drive(drive_url: str, save_path: str):\n","    \"\"\"\n","    Download a PDF from a Google Drive sharing link and save it locally.\n","    \"\"\"\n","    # Try pattern: /d/<FILE_ID>/\n","    match = re.search(r\"/d/([A-Za-z0-9_-]+)\", drive_url)\n","    if match:\n","        file_id = match.group(1)\n","    else:\n","        # Try pattern: ?id=<FILE_ID>\n","        match = re.search(r\"id=([A-Za-z0-9_-]+)\", drive_url)\n","        if match:\n","            file_id = match.group(1)\n","        else:\n","            raise ValueError(\"âŒ Could not extract file ID from the link.\")\n","\n","    download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n","    print(f\"ğŸ“¥ Downloading PDF (file ID {file_id})...\")\n","\n","    resp = requests.get(download_url)\n","    resp.raise_for_status()\n","\n","    with open(save_path, \"wb\") as f:\n","        f.write(resp.content)\n","\n","    print(f\"âœ… PDF downloaded â†’ {save_path}\")\n","\n","# Ask for the Drive link\n","drive_link = input(\"ğŸ“Œ Paste your Google Drive PDF link here: \").strip()\n","\n","# Make sure the data folder exists\n","DATA_DIR = \"data\"\n","os.makedirs(DATA_DIR, exist_ok=True)\n","\n","# Local path for the PDF\n","pdf_path = os.path.join(DATA_DIR, \"source.pdf\")\n","\n","# Download the PDF\n","download_pdf_from_drive(drive_link, pdf_path)"],"metadata":{"id":"i87yTehtwfp4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Break the PDF into semantic chunks (Step 4)\n","\n","The AI cannot use one giant block of text.  \n","Here you:\n","\n","- Load the PDF\n","- Use a **semantic splitter** to create â€œsmartâ€ chunks (not random splits)\n","- Label each chunk with simple metadata"],"metadata":{"id":"NAGD5bN3wmRs"}},{"cell_type":"code","source":["from llama_index.core import SimpleDirectoryReader\n","from llama_index.core.node_parser import SemanticSplitterNodeParser\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","\n","# Load the PDF as a document\n","documents = SimpleDirectoryReader(input_files=[pdf_path]).load_data()\n","print(f\"ğŸ“„ Loaded {len(documents)} document(s).\")\n","\n","# Embedding model for semantic splitting (can reuse the same model name)\n","semantic_embed = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n","\n","# Create a semantic splitter\n","parser = SemanticSplitterNodeParser(\n","    buffer_size=3,\n","    breakpoint_percentile_threshold=95,\n","    embed_model=semantic_embed,\n",")\n","\n","# Generate semantic nodes (chunks)\n","nodes = parser.get_nodes_from_documents(documents)\n","\n","# Add simple metadata to each chunk\n","for n in nodes:\n","    n.metadata[\"source\"] = pdf_path\n","    n.metadata[\"chunk_type\"] = \"semantic\"\n","\n","print(f\"ğŸ” Created {len(nodes)} high-quality semantic nodes.\")"],"metadata":{"id":"l-qrnKUjwqaR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Build the Query Fusion retriever (Step 5)\n","\n","Now you build the **search engine** that powers your RAG system.  \n","It uses **Query Fusion**:\n","\n","- Rewrites your question several ways\n","- Searches multiple times\n","- Fuses the best results\n"],"metadata":{"id":"2Wz7UU0Hwykw"}},{"cell_type":"code","source":["from llama_index.core.llama_pack import download_llama_pack\n","\n","# Download or load the Query Fusion pack\n","QueryRewritingRetrieverPack = download_llama_pack(\n","    \"QueryRewritingRetrieverPack\",\n","    \"./query_rewriting_pack\",\n",")\n","\n","# Create the advanced retriever using your nodes\n","query_rewriting_pack = QueryRewritingRetrieverPack(\n","    nodes,                      # semantic chunks from Step 4\n","    chunk_size=256,\n","    vector_similarity_top_k=8,\n","    fusion_similarity_top_k=8,\n","    num_queries=6,              # number of query rewrites\n",")\n","\n","print(\"ğŸš€ Advanced Query Fusion RAG Engine Ready!\")"],"metadata":{"id":"ut3EFoN5w-x9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Ask questions in an interactive loop (Step 6)\n","\n","Finally, you create a simple chat loop:\n","\n","- Type a question about the PDF\n","- The system runs the RAG pipeline\n","- You see a clear answer\n","- Type `end` to exit"],"metadata":{"id":"6jFsH5T3xDoE"}},{"cell_type":"code","source":["def safe_rag_run(question, retries=3):\n","    \"\"\"\n","    Run the RAG pipeline with basic retry logic.\n","    \"\"\"\n","    for attempt in range(retries):\n","        try:\n","            resp = query_rewriting_pack.run(question)\n","\n","            if resp is None or str(resp).strip() == \"\":\n","                raise ValueError(\"Empty LLM response.\")\n","\n","            return resp\n","\n","        except Exception as e:\n","            print(f\"âš ï¸ Error: {e}\")\n","            print(f\"ğŸ” Retrying ({attempt+1}/{retries})...\")\n","\n","    return \"âŒ Could not generate a valid answer after retries.\"\n","\n","print(\"\\nRAG Interactive Mode\")\n","print(\"Ask any question about your PDF.\")\n","print(\"Type 'end' to exit.\\n\")\n","\n","# Interactive Q&A loop\n","while True:\n","    user_question = input(\"ğŸŸ¦ Enter your question: \").strip()\n","\n","    if user_question.lower() == \"end\":\n","        print(\"\\nğŸ‘‹ Session ended.\")\n","        break\n","\n","    print(\"\\nğŸ” Retrieving answer...\\n\")\n","\n","    # Run the question through the RAG pipeline\n","    response = safe_rag_run(user_question)\n","\n","    print(\"\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n","    print(\"â“ QUESTION:\")\n","    print(user_question)\n","    print(\"\\nğŸ§  ANSWER:\")\n","    print(response)\n","    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")"],"metadata":{"id":"K7S6bKt_xJt7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***\n","\n","## 7. Example questions you can try\n","\n","Once everything is running, try questions like:\n","\n","- â€œWhat are the main goals in this document?â€\n","- â€œWhat does this policy say about attendance?â€\n","- â€œSummarise the key points in chapter one.â€\n","- â€œList all the responsibilities of students mentioned in this document.â€\n","- â€œHow is assessment described in this curriculum?â€\n","\n","***\n"],"metadata":{"id":"2b4krLVHxQHW"}}]}